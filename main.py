# PythonFilename: anki_ai_fields_update_v3.0_31Dec2025.py

import logging
from config import Config
from src.utils import setup_logging
from src.anki_client import fetch_note_ids, fetch_note_info, update_note_fields
from src.ai_client import analyze_text_with_ai

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    log_file_path = setup_logging()

    print(f"\n{'='*60}")
    print(f"ğŸ”¥ è„šæœ¬å¯åŠ¨ (v3.0æ­£å¼è¿è¡Œç‰ˆ) | æ—¥å¿—: {log_file_path}")
    print(f"ğŸ¯ ç›®æ ‡ç‰Œç»„: {Config.DECK_NAME}")
    print(f"{'='*60}\n")
    logging.info("=== è„šæœ¬å¯åŠ¨ (æ™ºèƒ½å¢é‡æ¨¡å¼) ===")

    note_ids = fetch_note_ids()
    # 1. è·å–noteIDåˆ—è¡¨
    if not note_ids:
            print("ğŸ¤·â€â™‚ï¸ æœªæ‰¾åˆ°ä»»ä½•å¡ç‰‡ã€‚")
            return
        
    # 2. è·å–è¯¦æƒ…
    notes_details = fetch_note_info(note_ids)
    # æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª note çš„è¯¦æƒ…å­—å…¸
    if not notes_details:
        print("âŒ è·å–å¡ç‰‡è¯¦æƒ…å¤±è´¥ã€‚")
        return

    total_count = len(notes_details)
    success_count = 0
    fail_count = 0
    skip_count = 0

    print(f"ğŸ“Š å…±åŠ è½½ {total_count} å¼ å¡ç‰‡ï¼Œå‡†å¤‡å¼€å§‹å¤„ç†...\n")

    # 3. å¾ªç¯å¤„ç† ï¼ˆè·³è¿‡å·²æœ‰4é¡¹å­—æ®µçš„noteï¼‰
    for index, note in enumerate(notes_details):
        # è¿›åº¦å‰ç¼€
        progress_prefix = f"[{index+1}/{total_count}]"

        # æå–å­—æ®µ
        note_id = note.get("noteId")
        fields = note.get("fields", {})
        
        text = fields.get("Text", {}).get("value", "").strip()
        context = fields.get("Context", {}).get("value", "").strip()
        
        mean_stats = fields.get("MeaningStats", {}).get("value", "").strip()
        synonyms = fields.get("Synonyms", {}).get("value", "").strip()
        gram_note = fields.get("GrammarNote", {}).get("value", "").strip()
        exam_sen = fields.get("ExampleSen", {}).get("value", "").strip()
        
        if not text or not context:
        # å³ä½¿æ˜¯å…¨é‡æ›´æ–°ï¼Œç©ºæ•°æ®ä¹Ÿæ²¡æ³•è·‘ï¼Œæ‰€ä»¥è¿™ä¸ªæ£€æŸ¥å¿…é¡»ç•™ç€
            logging.warning(f"âš ï¸ è·³è¿‡ (æ•°æ®ç¼ºå¤±): ID={note_id} | å•è¯: '{text}'")
            print(f"{progress_prefix} âš ï¸ è·³è¿‡: å•è¯æˆ–ä¾‹å¥ä¸ºç©º: ID={note_id} | å•è¯: '{text}'")
            continue
        
        if mean_stats and synonyms and gram_note and exam_sen:
            logging.info(f"â­ï¸ è·³è¿‡ (å·²å­˜åœ¨æ•°æ®): ID={note_id} | å•è¯: '{text}'")
            print(f"{progress_prefix} â­ï¸ è·³è¿‡: å·²æœ‰ AI æ•°æ®: ID={note_id} | å•è¯: '{text}'")
            skip_count += 1
            continue

        # A. å‘¼å« AI
        print(f"{progress_prefix} ğŸ¤– AIæ­£åœ¨æ€è€ƒ: '{text}'...", end="", flush=True)
        
        ai_json_data = analyze_text_with_ai(text, context)
        
        if not ai_json_data:
            print(" âŒ å¤±è´¥ (AIæ— å“åº”)")
            fail_count += 1
            continue
            
        # B. å¼ºåˆ¶å†™å…¥ Anki
        # å°† word ä¼ ç»™ update å‡½æ•°ï¼Œä¿è¯æ—¥å¿—é‡Œèƒ½çœ‹åˆ°å®ƒ
        if update_note_fields(note_id, ai_json_data, text):
            print(" âœ¨ å†™å…¥æˆåŠŸï¼")
            success_count += 1
        else:
            print(" âŒ å†™å…¥å¤±è´¥")
            fail_count += 1

    # 4. æ±‡æ€»ç»“æœ
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print(f"âœ… æˆåŠŸè¡¥å…¨: {success_count}")
    print(f"â­ï¸ è·³è¿‡å¤„ç†: {skip_count}")
    print(f"âŒ å¤±è´¥æ•°é‡: {fail_count}")
    print(f"{'='*60}")
    logging.info(f"=== ä»»åŠ¡ç»“æŸ: æˆåŠŸ {success_count} / è·³è¿‡ {skip_count} / å¤±è´¥ {fail_count} / æ€»è®¡ {total_count} ===")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.error(f"ç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼š{e}")
        print(f"âŒ ç¨‹åºå‘ç”Ÿé”™è¯¯ï¼š{e}")